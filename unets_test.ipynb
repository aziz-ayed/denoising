{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fiscal-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from unets import unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "secondary-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('dataset.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "received-better",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 51, 51)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['VIGNET_NOISELESS'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "certain-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train, im_val, target_train, target_val = train_test_split(dataset['VIGNETS_WITH_NOISE'], dataset['VIGNET_NOISELESS'],\n",
    "                                                              test_size=0.1, random_state=7)\n",
    "\n",
    "im_train = tf.reshape(tf.convert_to_tensor(im_train), [900, 51, 51, 1])/255\n",
    "target_train = tf.reshape(tf.convert_to_tensor(target_train), [900, 51, 51, 1])\n",
    "im_val = tf.reshape(tf.convert_to_tensor(im_val), [100, 51, 51, 1])/255\n",
    "target_val = tf.reshape(tf.convert_to_tensor(target_val), [100, 51, 51, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "burning-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels=1\n",
    "model=unet(input_size=(51,51,n_channels), lr=1e-3, bn=True, layers_n_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 2s 29ms/step - loss: 1.0673e-05 - keras_psnr: 49.9707 - keras_ssim: 0.9727 - val_loss: 1.0258e-05 - val_keras_psnr: 50.1250 - val_keras_ssim: 0.9753\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 9.7647e-06 - keras_psnr: 50.3266 - keras_ssim: 0.9753 - val_loss: 1.0256e-05 - val_keras_psnr: 50.1257 - val_keras_ssim: 0.9752\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 1.0226e-05 - keras_psnr: 50.1573 - keras_ssim: 0.9752 - val_loss: 1.0256e-05 - val_keras_psnr: 50.1257 - val_keras_ssim: 0.9752\n",
      "Epoch 4/30\n",
      "41/50 [=======================>......] - ETA: 0s - loss: 1.1036e-05 - keras_psnr: 49.7962 - keras_ssim: 0.9751"
     ]
    }
   ],
   "source": [
    "history = model.fit(im_train, target_train, validation_data=(im_val, target_val), batch_size=4, \n",
    "           epochs=30, steps_per_epoch=50)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss (training data)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (validation data)')\n",
    "plt.title('Loss of the Unets on the PSF Dataset')\n",
    "plt.ylabel('Loss value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_noiseless = model.predict(im_val)[99,:,:]\n",
    "one_star_noise = im_val[99,:,:]\n",
    "one_star_truth = target_val[99,:,:]\n",
    "second_star_noiseless = model.predict(im_val)[40,:,:]\n",
    "second_star_noise = im_val[40,:,:]\n",
    "second_star_truth = target_val[40,:,:]\n",
    "\n",
    "\n",
    "fig = plt.figure(num=0, figsize=(15,15))\n",
    "ax1 = fig.add_subplot(1,3,1)\n",
    "ax1.title.set_text('Noisy image')\n",
    "im1 = ax1.imshow(one_star_noise, interpolation='None')\n",
    "ax2 = fig.add_subplot(1,3,2)\n",
    "im2 = ax2.imshow(one_star_noiseless, interpolation='None')\n",
    "ax2.title.set_text('Denoised image')\n",
    "ax3 = fig.add_subplot(1,3,3)\n",
    "im3 = ax3.imshow(one_star_truth, interpolation='None')\n",
    "ax3.title.set_text('True image')\n",
    "ax4 = fig.add_subplot(3,3,1)\n",
    "ax4.title.set_text('Noisy image')\n",
    "im4 = ax4.imshow(second_star_noise, interpolation='None')\n",
    "ax5 = fig.add_subplot(3,3,2)\n",
    "im5 = ax5.imshow(second_star_noiseless, interpolation='None')\n",
    "ax5.title.set_text('Denoised image')\n",
    "ax6 = fig.add_subplot(3,3,3)\n",
    "im6 = ax6.imshow(second_star_truth, interpolation='None')\n",
    "ax6.title.set_text('True image')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-success",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-complaint",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
